# 📅 7/21 회고 – 정적 손 제스처 분류 모델 완성✨

오늘은 어제 만든 손 제스처 분류 모델을 더 예쁘고 똑똑하게 만들기 위해 노력했어!  
특히 실시간으로 빠르게 반응하면서도, 정확하게 분류해주는 **정적 손 제스처 분류기**를 만드는 게 목표였지 🙌

## 🧼 데이터 대청소 + 대량 수집
기존에는 데이터 양이 살짝 부족해서 모델이 헷갈려했어...  
그래서 오늘은 손 제스처 데이터를 무려 **15만 개 이상!** 추가로 수집했어.  
- 다양한 **조명**, **카메라 각도**, **손 위치**, **배경** 상황을 고려해서
- **None (무 제스처)** 데이터도 정말 많이 넣었어!  
  → 가만히 있을 때 이상한 이모지가 튀어나오면 화나니까...😤

## 🧠 모델 구조 설명
이번에는 전통적인 머신러닝(SVM, KNN) 모델이 아니라,
TensorFlow의 **Sequential API**를 활용해서 **깊이 있는 신경망**을 만들었어!

모델은 이런 구조로 만들었지:
1. 입력층은 관절의 상대 좌표 기반 feature vector
2. 중간에 Dense 층을 두 개 넣어서 뇌🧠를 튼튼하게 만들고
3. 과적합 방지를 위한 Dropout도 넣어줬어
4. 마지막 출력층에서는 softmax로 제스처 확률을 예측!

## 📊 학습 결과!
- 정확도는 무려 **99%** 달성!! (검증셋에서도 아주 잘 나옴)
- 예전엔 위치나 조명에 따라 인식이 안 됐는데, 이제는 그런 경우도 거의 없어졌어!
- 손을 살짝만 보여줘도 반응하는 게 너무 신기하고 귀여움...💕

## 💾 모델 변환과 최적화
학습이 끝난 모델을 바로 `tflite`로 변환해서 **온디바이스 추론**이 가능하도록 만들었어!
→ 스마트폰이나 로컬 환경에서도 **엄청 빠르게 실행돼서 실시간 이모지 표시가 가능**해졌어! 🎉

## 🔍 앞으로의 방향
정적 모델은 손이 멈춰 있을 때 제일 잘 작동해~  
그래서 나중에는 **동적 모델과 함께 사용할 수 있도록**  
"움직임이 없을 때만 정적 모델이 동작하도록" 로직을 만들 계획이야 🛠️

---

### 🤍 오늘의 귀여운 인사이트
- 무제스처(None)는 꼭 많이 넣어야 해! 안 그러면 괜히 이모지가 뿅 나와서 헷갈려!
- 정적 모델의 반응속도와 정확도를 동시에 잡았다는 점에서 아주 뿌듯한 하루였어 🐿️
