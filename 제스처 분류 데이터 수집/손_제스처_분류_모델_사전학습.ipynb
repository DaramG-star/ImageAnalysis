{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ce47a82",
   "metadata": {},
   "source": [
    "# ✋ 손 제스처 분류 모델 사전학습\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13008e8",
   "metadata": {},
   "source": [
    "## 📘 1. 프로젝트 개요\n",
    "\n",
    "이 노트북은 손 제스처 인식 모델을 학습하기 위한 사전 작업을 수행하는 목적을 가진다.  \n",
    "목표는 아래와 같다:\n",
    "\n",
    "- 다양한 손 제스처(예: fist, open_palm, ok, heart 등)를 정확하게 분류할 수 있는 모델 학습\n",
    "- **Webcam 기반 실시간 입력**을 지원하는 경량 모델로 구성\n",
    "- 실시간/오프라인 예측 모두 대응"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1743e8",
   "metadata": {},
   "source": [
    "## 📸 2. 데이터 수집 방법\n",
    "\n",
    "### ✅ 방법 1: 이미지 기반 수집 (사진 저장)\n",
    "\n",
    "- **설명**: 웹캠으로 손 제스처를 촬영하여 `.jpg` 형식으로 저장\n",
    "- **디렉토리 구조**: `dataset/{label_name}/image.jpg`\n",
    "\n",
    "**장점**:\n",
    "- 직관적이고 라벨 관리가 쉬움\n",
    "- 시각적 확인이 가능함\n",
    "\n",
    "**단점**:\n",
    "- 손 위치/각도에 따라 좌표가 달라져서 학습이 불안정할 수 있음\n",
    "- 배경, 조명 변화에 민감\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 방법 2: Mediapipe 기반 관절 특징 추출 + CSV 저장\n",
    "\n",
    "- **설명**: Mediapipe로 손 관절 21개의 위치를 추출하고, 각도/거리/벡터 방향 등 특징을 계산하여 `.csv`로 저장\n",
    "\n",
    "**장점**:\n",
    "- 배경/조명/회전에 덜 민감\n",
    "- 실시간 모델 구성에 매우 유리 (벡터화된 feature 사용)\n",
    "- 매우 가볍고 빠름\n",
    "\n",
    "**단점**:\n",
    "- 데이터 시각화가 어려움\n",
    "- 라벨링 오류 시 추적 어려움\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 방법 3: 외부 데이터셋 사용\n",
    "\n",
    "- 예: Bria Hand Gesture Dataset, Jester Dataset, ASL Alphabet Dataset\n",
    "\n",
    "**장점**:\n",
    "- 대량의 라벨링된 고품질 이미지 확보 가능\n",
    "- 학습 시간 절약\n",
    "\n",
    "**단점**:\n",
    "- 목적에 맞지 않는 라벨 구조일 수 있음\n",
    "- 데이터 전처리 필요\n",
    "- 모델 커스터마이징 어려움"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7e1535",
   "metadata": {},
   "source": [
    "## ✋ 3. 제스처 라벨 구성 예시\n",
    "\n",
    "| 라벨 이름 | 설명 |\n",
    "|-----------|------|\n",
    "| `fist` | 주먹 쥔 손 |\n",
    "| `open_palm` | 손을 편 상태 |\n",
    "| `ok` | OK 제스처 (엄지+검지 동그라미) |\n",
    "| `heart` | 손가락 하트 |\n",
    "| `victory` | V자 손 |\n",
    "| `promise` | 새끼손가락 걸기 |\n",
    "| `bad` | 엄지 아래로 |\n",
    "| `good` | 엄지 위로 |\n",
    "| `none` | 아무 동작이 없는 상태 (오류 방지용)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b53ce4f",
   "metadata": {},
   "source": [
    "## ⚙️ 4. 특징 추출 방식 비교\n",
    "\n",
    "| 방식 | 설명 | 장점 | 단점 |\n",
    "|------|------|------|------|\n",
    "| x, y 좌표 원본 | Mediapipe에서 받은 raw 좌표 | 구현이 간단함 | 위치/크기/회전에 민감 |\n",
    "| 상대 좌표 (벡터) | landmark 간 차이벡터 | 회전에 다소 강함 | 손이 많이 틀어지면 여전히 불안정 |\n",
    "| 각도 기반 | 세 관절로 이루어진 각도 사용 | 회전/크기 변화에 매우 강함 | 계산이 필요함 |\n",
    "| 거리 기반 | 손목-손끝, 손끝-손끝 거리 | 손 크기 등 비례 정보 잘 반영 | normalization 필요 |\n",
    "| 벡터 방향 | 방향성 표현 | 실시간 분류에 유리 | noise에 민감할 수 있음\n",
    "\n",
    "👉 최종 모델에서는 **각도 + 거리 + 벡터 방향 조합**을 사용하는 것이 가장 안정적"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39d74d7",
   "metadata": {},
   "source": [
    "## 🧪 5. 학습 방식\n",
    "\n",
    "### ✅ KNN (추천 ⭐)\n",
    "\n",
    "- `scikit-learn` 기반으로 학습\n",
    "```python\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "**장점**:\n",
    "- 간단하고 빠름\n",
    "- 소량 데이터로도 잘 작동\n",
    "\n",
    "**단점**:\n",
    "- 데이터가 많아지면 느려짐\n",
    "- 고차원일수록 거리 계산 정확도 저하 가능\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ MLP / SVM / RandomForest\n",
    "\n",
    "- Scikit-learn 또는 PyTorch 기반\n",
    "- 분류 정밀도 상승\n",
    "- 데이터가 많을 경우 추천\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ CNN (이미지 기반만 해당)\n",
    "\n",
    "- 이미지 원본을 학습하는 경우 사용\n",
    "- MobileNet, EfficientNet 등 사전학습 모델 가능\n",
    "\n",
    "**단점**:\n",
    "- 학습 시간/리소스 필요\n",
    "- 손만 잘라내는 전처리 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c2a1b5",
   "metadata": {},
   "source": [
    "## 🎯 6. 평가 방식\n",
    "\n",
    "- `train/val/test` 비율로 나눠서 평가\n",
    "- 정확도(`accuracy`), 정밀도(`precision`), 재현율(`recall`) 등 활용\n",
    "- Confusion Matrix 시각화 추천"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e542fb8",
   "metadata": {},
   "source": [
    "## 🛠️ 7. 실시간 예측\n",
    "\n",
    "- mediapipe + opencv + 학습된 모델로 실시간 카메라 입력 처리\n",
    "- 추론 속도가 중요한 경우 → 특징 기반 모델 추천\n",
    "- 예측 결과를 `cv2.putText()`로 화면에 표시 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc61dcf",
   "metadata": {},
   "source": [
    "## 📂 8. 파일 구조 예시\n",
    "\n",
    "```\n",
    "├── 손 제스처 분류 모델 사전학습.ipynb\n",
    "├── dataset/\n",
    "│   ├── fist/\n",
    "│   ├── ok/\n",
    "│   └── ...\n",
    "├── gesture_train.csv\n",
    "├── models/\n",
    "│   ├── knn_model.pkl\n",
    "│   └── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5922c2ae",
   "metadata": {},
   "source": [
    "## 📌 9. 요약\n",
    "\n",
    "| 항목 | 추천 방법 |\n",
    "|------|-----------|\n",
    "| 수집 방식 | Mediapipe로 관절 추출 + CSV 저장 |\n",
    "| 특징 | 각도 + 거리 + 벡터 방향 조합 |\n",
    "| 모델 | KNN 또는 RandomForest |\n",
    "| 실시간 용도 | 특징 기반 분류 모델 |\n",
    "| none 라벨 | 실시간 분류일 경우 필수 |\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
