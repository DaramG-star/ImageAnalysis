{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef9b6bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 기준점: 코 끝 (landmark index 1)\n",
    "def extract_relative_face_keypoints(landmarks):\n",
    "    base = landmarks[1]  # 기준점 (코 끝)\n",
    "    relative = []\n",
    "    for lm in landmarks:\n",
    "        dx = lm.x - base.x\n",
    "        dy = lm.y - base.y\n",
    "        relative.append([dx, dy])\n",
    "    return np.array(relative).flatten()  # 936개 (468점 x 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1d76b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "laugh: 100%|██████████| 511/511 [00:03<00:00, 142.74it/s]\n",
      "serious: 100%|██████████| 509/509 [00:03<00:00, 144.44it/s]\n",
      "surprise: 100%|██████████| 539/539 [00:03<00:00, 143.05it/s]\n",
      "yawn: 100%|██████████| 292/292 [00:01<00:00, 147.01it/s]\n",
      "none: 100%|██████████| 338/338 [00:02<00:00, 147.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 데이터셋 shape: (2157, 936) (2157,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from tqdm import tqdm\n",
    "\n",
    "LABELS = ['laugh', 'serious', 'surprise', 'yawn', 'none']\n",
    "DATA_PATH = '../face_data'\n",
    "X, y = [], []\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True)\n",
    "\n",
    "for idx, label in enumerate(LABELS):\n",
    "    folder = os.path.join(DATA_PATH, label)\n",
    "    for file in tqdm(os.listdir(folder), desc=label):\n",
    "        if not file.endswith('.jpg'):\n",
    "            continue\n",
    "        img_path = os.path.join(folder, file)\n",
    "        img = cv2.imread(img_path)\n",
    "        rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        results = face_mesh.process(rgb)\n",
    "        if results.multi_face_landmarks:\n",
    "            landmarks = results.multi_face_landmarks[0].landmark\n",
    "            keypoints = extract_relative_face_keypoints(landmarks)\n",
    "            X.append(keypoints)\n",
    "            y.append(idx)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(\"✅ 데이터셋 shape:\", X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12ff6a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SSAFY\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2924 - loss: 1.4983 - val_accuracy: 0.5069 - val_loss: 1.3039\n",
      "Epoch 2/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4572 - loss: 1.2815 - val_accuracy: 0.5856 - val_loss: 1.1517\n",
      "Epoch 3/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5480 - loss: 1.1145 - val_accuracy: 0.6319 - val_loss: 0.9426\n",
      "Epoch 4/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6588 - loss: 0.8821 - val_accuracy: 0.6713 - val_loss: 0.7850\n",
      "Epoch 5/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6921 - loss: 0.7669 - val_accuracy: 0.6921 - val_loss: 0.7526\n",
      "Epoch 6/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7191 - loss: 0.7116 - val_accuracy: 0.7685 - val_loss: 0.6374\n",
      "Epoch 7/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7440 - loss: 0.6629 - val_accuracy: 0.7500 - val_loss: 0.6500\n",
      "Epoch 8/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7467 - loss: 0.6362 - val_accuracy: 0.7616 - val_loss: 0.5880\n",
      "Epoch 9/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7667 - loss: 0.5905 - val_accuracy: 0.7940 - val_loss: 0.5469\n",
      "Epoch 10/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7597 - loss: 0.6133 - val_accuracy: 0.7824 - val_loss: 0.5466\n",
      "Epoch 11/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7589 - loss: 0.5538 - val_accuracy: 0.7523 - val_loss: 0.5543\n",
      "Epoch 12/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7776 - loss: 0.5499 - val_accuracy: 0.7454 - val_loss: 0.6047\n",
      "Epoch 13/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7703 - loss: 0.5953 - val_accuracy: 0.8009 - val_loss: 0.5276\n",
      "Epoch 14/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7938 - loss: 0.5356 - val_accuracy: 0.8079 - val_loss: 0.5049\n",
      "Epoch 15/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7908 - loss: 0.5192 - val_accuracy: 0.8333 - val_loss: 0.4744\n",
      "Epoch 16/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8242 - loss: 0.4865 - val_accuracy: 0.8287 - val_loss: 0.4745\n",
      "Epoch 17/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7862 - loss: 0.5471 - val_accuracy: 0.8009 - val_loss: 0.5146\n",
      "Epoch 18/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7956 - loss: 0.5195 - val_accuracy: 0.8287 - val_loss: 0.4650\n",
      "Epoch 19/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7904 - loss: 0.5073 - val_accuracy: 0.8264 - val_loss: 0.4543\n",
      "Epoch 20/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8161 - loss: 0.4770 - val_accuracy: 0.7639 - val_loss: 0.5548\n",
      "Epoch 21/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7957 - loss: 0.5016 - val_accuracy: 0.8495 - val_loss: 0.4506\n",
      "Epoch 22/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8288 - loss: 0.4329 - val_accuracy: 0.8125 - val_loss: 0.4792\n",
      "Epoch 23/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8240 - loss: 0.4506 - val_accuracy: 0.8403 - val_loss: 0.4427\n",
      "Epoch 24/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8275 - loss: 0.4635 - val_accuracy: 0.8171 - val_loss: 0.4424\n",
      "Epoch 25/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8118 - loss: 0.4486 - val_accuracy: 0.8264 - val_loss: 0.4877\n",
      "Epoch 26/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8182 - loss: 0.4651 - val_accuracy: 0.8287 - val_loss: 0.4627\n",
      "Epoch 27/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8221 - loss: 0.4388 - val_accuracy: 0.8333 - val_loss: 0.4261\n",
      "Epoch 28/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8185 - loss: 0.4533 - val_accuracy: 0.8148 - val_loss: 0.4418\n",
      "Epoch 29/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8429 - loss: 0.4150 - val_accuracy: 0.8380 - val_loss: 0.4361\n",
      "Epoch 30/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8148 - loss: 0.4443 - val_accuracy: 0.8426 - val_loss: 0.4274\n",
      "Epoch 31/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8332 - loss: 0.4258 - val_accuracy: 0.8426 - val_loss: 0.4172\n",
      "Epoch 32/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8443 - loss: 0.4096 - val_accuracy: 0.7940 - val_loss: 0.4759\n",
      "Epoch 33/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8390 - loss: 0.4372 - val_accuracy: 0.8148 - val_loss: 0.4461\n",
      "Epoch 34/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8465 - loss: 0.4091 - val_accuracy: 0.8472 - val_loss: 0.4217\n",
      "Epoch 35/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8124 - loss: 0.4483 - val_accuracy: 0.8287 - val_loss: 0.4491\n",
      "Epoch 36/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8288 - loss: 0.4298 - val_accuracy: 0.8310 - val_loss: 0.4366\n",
      "Epoch 37/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8117 - loss: 0.4549 - val_accuracy: 0.8333 - val_loss: 0.4398\n",
      "Epoch 38/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8331 - loss: 0.4272 - val_accuracy: 0.8356 - val_loss: 0.4311\n",
      "Epoch 39/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8355 - loss: 0.4248 - val_accuracy: 0.8495 - val_loss: 0.4036\n",
      "Epoch 40/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8424 - loss: 0.4179 - val_accuracy: 0.8171 - val_loss: 0.4836\n",
      "Epoch 41/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8385 - loss: 0.4029 - val_accuracy: 0.8241 - val_loss: 0.4431\n",
      "Epoch 42/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8357 - loss: 0.4145 - val_accuracy: 0.8565 - val_loss: 0.3915\n",
      "Epoch 43/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8351 - loss: 0.4156 - val_accuracy: 0.8426 - val_loss: 0.3969\n",
      "Epoch 44/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8305 - loss: 0.4101 - val_accuracy: 0.8495 - val_loss: 0.4168\n",
      "Epoch 45/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8518 - loss: 0.3810 - val_accuracy: 0.8380 - val_loss: 0.3912\n",
      "Epoch 46/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8394 - loss: 0.3958 - val_accuracy: 0.8565 - val_loss: 0.3832\n",
      "Epoch 47/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8482 - loss: 0.3721 - val_accuracy: 0.8218 - val_loss: 0.4649\n",
      "Epoch 48/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8180 - loss: 0.4325 - val_accuracy: 0.8542 - val_loss: 0.3955\n",
      "Epoch 49/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8445 - loss: 0.4126 - val_accuracy: 0.8241 - val_loss: 0.4572\n",
      "Epoch 50/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8335 - loss: 0.4233 - val_accuracy: 0.8611 - val_loss: 0.3979\n",
      "Epoch 51/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8489 - loss: 0.3959 - val_accuracy: 0.7917 - val_loss: 0.4818\n",
      "Epoch 52/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8372 - loss: 0.4117 - val_accuracy: 0.8542 - val_loss: 0.3820\n",
      "Epoch 53/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8416 - loss: 0.4247 - val_accuracy: 0.8449 - val_loss: 0.3938\n",
      "Epoch 54/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8455 - loss: 0.3705 - val_accuracy: 0.8356 - val_loss: 0.3985\n",
      "Epoch 55/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8548 - loss: 0.3799 - val_accuracy: 0.8287 - val_loss: 0.4587\n",
      "Epoch 56/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8343 - loss: 0.4008 - val_accuracy: 0.8472 - val_loss: 0.4049\n",
      "Epoch 57/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8473 - loss: 0.3973 - val_accuracy: 0.8495 - val_loss: 0.4095\n",
      "Epoch 58/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8624 - loss: 0.3737 - val_accuracy: 0.8542 - val_loss: 0.3834\n",
      "Epoch 59/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8485 - loss: 0.3812 - val_accuracy: 0.8657 - val_loss: 0.3759\n",
      "Epoch 60/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8531 - loss: 0.3872 - val_accuracy: 0.8519 - val_loss: 0.3937\n",
      "Epoch 61/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8445 - loss: 0.3798 - val_accuracy: 0.8426 - val_loss: 0.4316\n",
      "Epoch 62/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8264 - loss: 0.4337 - val_accuracy: 0.8495 - val_loss: 0.3961\n",
      "Epoch 63/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8558 - loss: 0.3713 - val_accuracy: 0.8519 - val_loss: 0.3894\n",
      "Epoch 64/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8640 - loss: 0.3506 - val_accuracy: 0.8519 - val_loss: 0.3909\n",
      "Epoch 65/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8677 - loss: 0.3503 - val_accuracy: 0.8380 - val_loss: 0.4227\n",
      "Epoch 66/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8407 - loss: 0.4031 - val_accuracy: 0.8472 - val_loss: 0.4169\n",
      "Epoch 67/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8567 - loss: 0.3701 - val_accuracy: 0.8449 - val_loss: 0.3811\n",
      "Epoch 68/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8611 - loss: 0.3482 - val_accuracy: 0.8519 - val_loss: 0.3652\n",
      "Epoch 69/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8646 - loss: 0.3601 - val_accuracy: 0.8588 - val_loss: 0.3779\n",
      "Epoch 70/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8758 - loss: 0.3329 - val_accuracy: 0.8356 - val_loss: 0.4189\n",
      "Epoch 71/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8553 - loss: 0.3743 - val_accuracy: 0.8519 - val_loss: 0.3724\n",
      "Epoch 72/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8641 - loss: 0.3486 - val_accuracy: 0.8495 - val_loss: 0.3852\n",
      "Epoch 73/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8581 - loss: 0.3725 - val_accuracy: 0.8519 - val_loss: 0.3617\n",
      "Epoch 74/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8568 - loss: 0.3593 - val_accuracy: 0.8657 - val_loss: 0.3585\n",
      "Epoch 75/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8709 - loss: 0.3384 - val_accuracy: 0.8681 - val_loss: 0.3568\n",
      "Epoch 76/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8736 - loss: 0.3425 - val_accuracy: 0.8380 - val_loss: 0.4349\n",
      "Epoch 77/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8616 - loss: 0.3585 - val_accuracy: 0.8611 - val_loss: 0.3659\n",
      "Epoch 78/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8748 - loss: 0.3338 - val_accuracy: 0.8565 - val_loss: 0.3569\n",
      "Epoch 79/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8656 - loss: 0.3346 - val_accuracy: 0.8611 - val_loss: 0.3615\n",
      "Epoch 80/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8606 - loss: 0.3462 - val_accuracy: 0.8611 - val_loss: 0.3560\n",
      "Epoch 81/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8628 - loss: 0.3134 - val_accuracy: 0.8472 - val_loss: 0.4199\n",
      "Epoch 82/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8696 - loss: 0.3401 - val_accuracy: 0.8588 - val_loss: 0.3843\n",
      "Epoch 83/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8526 - loss: 0.3462 - val_accuracy: 0.8565 - val_loss: 0.3994\n",
      "Epoch 84/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8476 - loss: 0.3921 - val_accuracy: 0.8704 - val_loss: 0.3631\n",
      "Epoch 85/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8721 - loss: 0.3450 - val_accuracy: 0.8565 - val_loss: 0.3837\n",
      "Epoch 86/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8679 - loss: 0.3443 - val_accuracy: 0.8565 - val_loss: 0.3860\n",
      "Epoch 87/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8480 - loss: 0.3809 - val_accuracy: 0.8657 - val_loss: 0.3589\n",
      "Epoch 88/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8723 - loss: 0.3126 - val_accuracy: 0.8750 - val_loss: 0.3509\n",
      "Epoch 89/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8802 - loss: 0.3307 - val_accuracy: 0.8704 - val_loss: 0.3416\n",
      "Epoch 90/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8671 - loss: 0.3559 - val_accuracy: 0.8704 - val_loss: 0.3493\n",
      "Epoch 91/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8494 - loss: 0.3864 - val_accuracy: 0.8634 - val_loss: 0.3572\n",
      "Epoch 92/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8746 - loss: 0.3220 - val_accuracy: 0.8657 - val_loss: 0.3750\n",
      "Epoch 93/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8648 - loss: 0.3535 - val_accuracy: 0.8657 - val_loss: 0.3550\n",
      "Epoch 94/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8718 - loss: 0.3342 - val_accuracy: 0.8495 - val_loss: 0.4079\n",
      "Epoch 95/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8672 - loss: 0.3349 - val_accuracy: 0.8588 - val_loss: 0.3905\n",
      "Epoch 96/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8810 - loss: 0.3317 - val_accuracy: 0.8634 - val_loss: 0.3915\n",
      "Epoch 97/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8583 - loss: 0.3445 - val_accuracy: 0.8704 - val_loss: 0.3440\n",
      "Epoch 98/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8699 - loss: 0.3274 - val_accuracy: 0.8634 - val_loss: 0.3950\n",
      "Epoch 99/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8684 - loss: 0.3556 - val_accuracy: 0.8704 - val_loss: 0.3519\n",
      "Epoch 100/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8800 - loss: 0.3226 - val_accuracy: 0.8657 - val_loss: 0.3637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_cat = to_categorical(y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y_cat, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(len(LABELS), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "model.save('face_expression_landmark_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "427a9103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎥 실시간 표정 추론 시작 — 'q' 눌러 종료\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import mediapipe as mp\n",
    "\n",
    "LABELS = ['laugh', 'serious', 'surprise', 'yawn', 'none']\n",
    "EMOJIS = {\n",
    "    \"laugh\": \":D\",         \n",
    "    \"serious\": \"-_-\",\n",
    "    \"surprise\": \"!!\",\n",
    "    \"yawn\": \"Zz\",\n",
    "    \"none\": \"...\"\n",
    "}\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model('face_expression_landmark_model.h5')\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=False, min_detection_confidence=0.7)\n",
    "\n",
    "def extract_relative_keypoints(landmarks):\n",
    "    base = landmarks[1]\n",
    "    relative = []\n",
    "    for lm in landmarks:\n",
    "        dx = lm.x - base.x\n",
    "        dy = lm.y - base.y\n",
    "        relative.append([dx, dy])\n",
    "    return np.array(relative).flatten()\n",
    "\n",
    "MOUTH_IDX = [13, 14, 78, 82, 87, 88, 95, 61, 146, 91, 181, 308, 317, 312, 311, 402]\n",
    "\n",
    "def is_mouth_covered(landmarks, threshold=0.003):\n",
    "    base = landmarks[1]\n",
    "    mouth_movement = 0\n",
    "    for i in MOUTH_IDX:\n",
    "        lm = landmarks[i]\n",
    "        dx = abs(lm.x - base.x)\n",
    "        dy = abs(lm.y - base.y)\n",
    "        mouth_movement += dx + dy\n",
    "    avg_move = mouth_movement / len(MOUTH_IDX)\n",
    "    return avg_move < threshold\n",
    "\n",
    "def is_mouth_closed(landmarks, threshold=0.015):\n",
    "    upper_lip = landmarks[13].y\n",
    "    lower_lip = landmarks[14].y\n",
    "    return abs(lower_lip - upper_lip) < threshold\n",
    "\n",
    "mouth_labels = ['laugh', 'yawn', 'surprise']\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "print(\"🎥 실시간 표정 추론 시작 — 'q' 눌러 종료\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        landmarks = results.multi_face_landmarks[0].landmark\n",
    "\n",
    "        if is_mouth_covered(landmarks):\n",
    "            label = \"mouth covered\"\n",
    "            cv2.putText(frame, label, (30, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 255), 2)\n",
    "        else:\n",
    "            keypoints = extract_relative_keypoints(landmarks)\n",
    "            input_data = keypoints.reshape(1, -1).astype(np.float32)\n",
    "\n",
    "            pred_probs = model.predict(input_data, verbose=0)\n",
    "            pred = np.argmax(pred_probs)\n",
    "            conf = np.max(pred_probs)\n",
    "            label = LABELS[pred]\n",
    "\n",
    "            if conf >= 0.8:\n",
    "                # 입 벌림 없는 상태에서 mouth-required label은 억제\n",
    "                if label in mouth_labels and is_mouth_closed(landmarks):\n",
    "                    cv2.putText(frame, \"Uncertain (mouth closed)\", (30, 50),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1.2, (100, 100, 100), 2)\n",
    "                else:\n",
    "                    emoji = EMOJIS[label]\n",
    "                    cv2.putText(frame, f\"{emoji} {label} ({conf:.2f})\", (30, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)\n",
    "\n",
    "            else:\n",
    "                cv2.putText(frame, \"Uncertain\", (30, 50),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.2, (100, 100, 100), 2)\n",
    "    else:\n",
    "        cv2.putText(frame, \"No face detected\", (30, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Expression (Landmark)\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bf08b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
