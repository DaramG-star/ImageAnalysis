{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b303a48",
   "metadata": {},
   "source": [
    "### 얼굴 필터 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6109c794",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SSAFY\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 55\u001b[0m\n\u001b[0;32m     52\u001b[0m         filter_h \u001b[38;5;241m=\u001b[39m y2 \u001b[38;5;241m-\u001b[39m y1\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filter_w \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m filter_h \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 55\u001b[0m             \u001b[43moverlay_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_h\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSquirrel Filter 🐿️\u001b[39m\u001b[38;5;124m'\u001b[39m, frame)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m, in \u001b[0;36moverlay_filter\u001b[1;34m(frame, filter_img, x, y, w, h)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moverlay_filter\u001b[39m(frame, filter_img, x, y, w, h):\n\u001b[1;32m---> 15\u001b[0m     filter_resized \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilter_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):  \u001b[38;5;66;03m# BGR 채널\u001b[39;00m\n\u001b[0;32m     18\u001b[0m         frame[y:y\u001b[38;5;241m+\u001b[39mh, x:x\u001b[38;5;241m+\u001b[39mw, c] \u001b[38;5;241m=\u001b[39m frame[y:y\u001b[38;5;241m+\u001b[39mh, x:x\u001b[38;5;241m+\u001b[39mw, c] \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m filter_resized[:, :, \u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.0\u001b[39m) \u001b[38;5;241m+\u001b[39m \\\n\u001b[0;32m     19\u001b[0m                                  filter_resized[:, :, c] \u001b[38;5;241m*\u001b[39m (filter_resized[:, :, \u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.0\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# 람쥐 필터 이미지 (투명 PNG)\n",
    "filter_img = cv2.imread('squirrel1.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# mediapipe 얼굴 검출 초기화\n",
    "mp_face = mp.solutions.face_detection\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "face_detection = mp_face.FaceDetection(model_selection=0, min_detection_confidence=0.5)\n",
    "\n",
    "# 필터 오버레이 함수\n",
    "def overlay_filter(frame, filter_img, x, y, w, h):\n",
    "    filter_resized = cv2.resize(filter_img, (w, h))\n",
    "\n",
    "    for c in range(3):  # BGR 채널\n",
    "        frame[y:y+h, x:x+w, c] = frame[y:y+h, x:x+w, c] * (1 - filter_resized[:, :, 3]/255.0) + \\\n",
    "                                 filter_resized[:, :, c] * (filter_resized[:, :, 3]/255.0)\n",
    "\n",
    "# 웹캠 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 좌우 반전\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w, _ = frame.shape\n",
    "\n",
    "    # 얼굴 감지\n",
    "    results = face_detection.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    if results.detections:\n",
    "        for detection in results.detections:\n",
    "            bboxC = detection.location_data.relative_bounding_box\n",
    "            x = int(bboxC.xmin * w)\n",
    "            y = int(bboxC.ymin * h)\n",
    "            box_w = int(bboxC.width * w)\n",
    "            box_h = int(bboxC.height * h)\n",
    "\n",
    "            # 얼굴 기준으로 필터 위치 조정 (이마 쪽으로 위로 이동)\n",
    "            offset_y = int(box_h * 0.4)\n",
    "            x1 = max(0, x - int(box_w * 0.2))\n",
    "            y1 = max(0, y - offset_y)\n",
    "            x2 = min(w, x1 + int(box_w * 1.4))\n",
    "            y2 = min(h, y1 + int(box_h * 1.5))\n",
    "\n",
    "            filter_w = x2 - x1\n",
    "            filter_h = y2 - y1\n",
    "\n",
    "            if filter_w > 0 and filter_h > 0:\n",
    "                overlay_filter(frame, filter_img, x1, y1, filter_w, filter_h)\n",
    "\n",
    "    cv2.imshow('Squirrel Filter 🐿️', frame)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c16b9e",
   "metadata": {},
   "source": [
    "#### 눈감으면 다른 가면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91c573b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# 얼굴 필터 이미지 로드\n",
    "filters = {\n",
    "    \"neutral\": cv2.imread('neutral.png', cv2.IMREAD_UNCHANGED),\n",
    "    \"eyeclosed_neutral\": cv2.imread('eyeclosed_neutral.png', cv2.IMREAD_UNCHANGED),\n",
    "    \"mouth_open\": cv2.imread('mouth_open.png', cv2.IMREAD_UNCHANGED),\n",
    "    \"eyeclosed_mouthopen\": cv2.imread('eyeclosed_mouthopen.png', cv2.IMREAD_UNCHANGED),\n",
    "    \"happy\": cv2.imread('happy.png', cv2.IMREAD_UNCHANGED),\n",
    "    \"eyeclosed_happy\": cv2.imread('eyeclosed_happy.png', cv2.IMREAD_UNCHANGED),\n",
    "    \"veryhappy\": cv2.imread('veryhappy.png', cv2.IMREAD_UNCHANGED),\n",
    "}\n",
    "\n",
    "# Mediapipe 초기화\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_hands = mp.solutions.hands\n",
    "face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True)\n",
    "hands = mp_hands.Hands(max_num_hands=2, min_detection_confidence=0.7)\n",
    "\n",
    "# EAR 계산 함수\n",
    "def get_ear(landmarks, indices, w, h):\n",
    "    pts = [(int(landmarks[i].x * w), int(landmarks[i].y * h)) for i in indices]\n",
    "    A = np.linalg.norm(np.array(pts[1]) - np.array(pts[5]))\n",
    "    B = np.linalg.norm(np.array(pts[2]) - np.array(pts[4]))\n",
    "    C = np.linalg.norm(np.array(pts[0]) - np.array(pts[3]))\n",
    "    return (A + B) / (2.0 * C)\n",
    "\n",
    "# 입 벌림 판단 함수\n",
    "def get_mouth_opening(landmarks, h):\n",
    "    return abs(landmarks[13].y - landmarks[14].y) * h\n",
    "\n",
    "# 미소 판단 함수\n",
    "def is_smiling(landmarks, w, h):\n",
    "    left = landmarks[61]\n",
    "    right = landmarks[291]\n",
    "    top = landmarks[13]\n",
    "    bottom = landmarks[14]\n",
    "    mouth_width = abs(right.x - left.x) * w\n",
    "    mouth_height = abs(bottom.y - top.y) * h\n",
    "    ratio = mouth_width / (mouth_height + 1e-6)\n",
    "    return ratio > 2.2\n",
    "\n",
    "# 손을 갈색으로 칠하는 함수\n",
    "def draw_hand_mask(image, hand_landmarks, color=(60, 40, 20), alpha=0.5):\n",
    "    h, w, _ = image.shape\n",
    "    overlay = image.copy()\n",
    "    for lm in hand_landmarks.landmark:\n",
    "        x, y = int(lm.x * w), int(lm.y * h)\n",
    "        cv2.circle(overlay, (x, y), 20, color, -1)\n",
    "    cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0, image)\n",
    "\n",
    "# 필터 오버레이 함수\n",
    "def overlay_filter(frame, filter_img, x, y, w, h):\n",
    "    filter_resized = cv2.resize(filter_img, (w, h))\n",
    "    alpha = filter_resized[:, :, 3] / 255.0\n",
    "    for c in range(3):\n",
    "        frame[y:y+h, x:x+w, c] = (1 - alpha) * frame[y:y+h, x:x+w, c] + alpha * filter_resized[:, :, c]\n",
    "\n",
    "# 웹캠 실행\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w, _ = frame.shape\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    face_result = face_mesh.process(rgb)\n",
    "    hand_result = hands.process(rgb)\n",
    "\n",
    "    # 손 갈색 처리\n",
    "    if hand_result.multi_hand_landmarks:\n",
    "        for hand in hand_result.multi_hand_landmarks:\n",
    "            draw_hand_mask(frame, hand)\n",
    "\n",
    "    # 얼굴 필터 처리\n",
    "    if face_result.multi_face_landmarks:\n",
    "        for landmarks in face_result.multi_face_landmarks:\n",
    "            ear_l = get_ear(landmarks.landmark, [33, 160, 158, 133, 153, 144], w, h)\n",
    "            ear_r = get_ear(landmarks.landmark, [362, 385, 387, 263, 373, 380], w, h)\n",
    "            eye_closed = (ear_l + ear_r) / 2 < 0.2\n",
    "            mouth_open = get_mouth_opening(landmarks.landmark, h) > 15\n",
    "            smiling = is_smiling(landmarks.landmark, w, h)\n",
    "\n",
    "            # 얼굴 위치 계산\n",
    "            xs = [lm.x for lm in landmarks.landmark]\n",
    "            ys = [lm.y for lm in landmarks.landmark]\n",
    "            min_x, max_x = int(min(xs) * w), int(max(xs) * w)\n",
    "            min_y, max_y = int(min(ys) * h), int(max(ys) * h)\n",
    "            face_w, face_h = max_x - min_x, max_y - min_y\n",
    "            cx = max(0, min(min_x - face_w // 10, w - 1))\n",
    "            cy = max(0, min(min_y - face_h // 3, h - 1))\n",
    "            cw = min(int(face_w * 1.2), w - cx)\n",
    "            ch = min(int(face_h * 1.5), h - cy)\n",
    "\n",
    "            # 표정에 맞는 키 선택\n",
    "            if smiling and mouth_open:\n",
    "                key = \"veryhappy\"\n",
    "            elif smiling and eye_closed:\n",
    "                key = \"eyeclosed_happy\"\n",
    "            elif smiling:\n",
    "                key = \"happy\"\n",
    "            elif mouth_open and eye_closed:\n",
    "                key = \"eyeclosed_mouthopen\"\n",
    "            elif mouth_open:\n",
    "                key = \"mouth_open\"\n",
    "            elif eye_closed:\n",
    "                key = \"eyeclosed_neutral\"\n",
    "            else:\n",
    "                key = \"neutral\"\n",
    "\n",
    "            # 필터 오버레이\n",
    "            overlay_filter(frame, filters[key], cx, cy, cw, ch)\n",
    "\n",
    "    cv2.imshow(\"🐿️ Squirrel Vtuber\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed961d6a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
