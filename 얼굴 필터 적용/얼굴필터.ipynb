{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b303a48",
   "metadata": {},
   "source": [
    "### ÏñºÍµ¥ ÌïÑÌÑ∞ Ï†ÅÏö©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6109c794",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SSAFY\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 55\u001b[0m\n\u001b[0;32m     52\u001b[0m         filter_h \u001b[38;5;241m=\u001b[39m y2 \u001b[38;5;241m-\u001b[39m y1\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filter_w \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m filter_h \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 55\u001b[0m             \u001b[43moverlay_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_h\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSquirrel Filter üêøÔ∏è\u001b[39m\u001b[38;5;124m'\u001b[39m, frame)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m, in \u001b[0;36moverlay_filter\u001b[1;34m(frame, filter_img, x, y, w, h)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moverlay_filter\u001b[39m(frame, filter_img, x, y, w, h):\n\u001b[1;32m---> 15\u001b[0m     filter_resized \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilter_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):  \u001b[38;5;66;03m# BGR Ï±ÑÎÑê\u001b[39;00m\n\u001b[0;32m     18\u001b[0m         frame[y:y\u001b[38;5;241m+\u001b[39mh, x:x\u001b[38;5;241m+\u001b[39mw, c] \u001b[38;5;241m=\u001b[39m frame[y:y\u001b[38;5;241m+\u001b[39mh, x:x\u001b[38;5;241m+\u001b[39mw, c] \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m filter_resized[:, :, \u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.0\u001b[39m) \u001b[38;5;241m+\u001b[39m \\\n\u001b[0;32m     19\u001b[0m                                  filter_resized[:, :, c] \u001b[38;5;241m*\u001b[39m (filter_resized[:, :, \u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.0\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# ÎûåÏ•ê ÌïÑÌÑ∞ Ïù¥ÎØ∏ÏßÄ (Ìà¨Î™Ö PNG)\n",
    "filter_img = cv2.imread('squirrel1.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# mediapipe ÏñºÍµ¥ Í≤ÄÏ∂ú Ï¥àÍ∏∞Ìôî\n",
    "mp_face = mp.solutions.face_detection\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "face_detection = mp_face.FaceDetection(model_selection=0, min_detection_confidence=0.5)\n",
    "\n",
    "# ÌïÑÌÑ∞ Ïò§Î≤ÑÎ†àÏù¥ Ìï®Ïàò\n",
    "def overlay_filter(frame, filter_img, x, y, w, h):\n",
    "    filter_resized = cv2.resize(filter_img, (w, h))\n",
    "\n",
    "    for c in range(3):  # BGR Ï±ÑÎÑê\n",
    "        frame[y:y+h, x:x+w, c] = frame[y:y+h, x:x+w, c] * (1 - filter_resized[:, :, 3]/255.0) + \\\n",
    "                                 filter_resized[:, :, c] * (filter_resized[:, :, 3]/255.0)\n",
    "\n",
    "# ÏõπÏ∫† Ïó¥Í∏∞\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Ï¢åÏö∞ Î∞òÏ†Ñ\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w, _ = frame.shape\n",
    "\n",
    "    # ÏñºÍµ¥ Í∞êÏßÄ\n",
    "    results = face_detection.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    if results.detections:\n",
    "        for detection in results.detections:\n",
    "            bboxC = detection.location_data.relative_bounding_box\n",
    "            x = int(bboxC.xmin * w)\n",
    "            y = int(bboxC.ymin * h)\n",
    "            box_w = int(bboxC.width * w)\n",
    "            box_h = int(bboxC.height * h)\n",
    "\n",
    "            # ÏñºÍµ¥ Í∏∞Ï§ÄÏúºÎ°ú ÌïÑÌÑ∞ ÏúÑÏπò Ï°∞Ï†ï (Ïù¥Îßà Ï™ΩÏúºÎ°ú ÏúÑÎ°ú Ïù¥Îèô)\n",
    "            offset_y = int(box_h * 0.4)\n",
    "            x1 = max(0, x - int(box_w * 0.2))\n",
    "            y1 = max(0, y - offset_y)\n",
    "            x2 = min(w, x1 + int(box_w * 1.4))\n",
    "            y2 = min(h, y1 + int(box_h * 1.5))\n",
    "\n",
    "            filter_w = x2 - x1\n",
    "            filter_h = y2 - y1\n",
    "\n",
    "            if filter_w > 0 and filter_h > 0:\n",
    "                overlay_filter(frame, filter_img, x1, y1, filter_w, filter_h)\n",
    "\n",
    "    cv2.imshow('Squirrel Filter üêøÔ∏è', frame)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c16b9e",
   "metadata": {},
   "source": [
    "#### ÎààÍ∞êÏúºÎ©¥ Îã§Î•∏ Í∞ÄÎ©¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91c573b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# ÏñºÍµ¥ ÌïÑÌÑ∞ Ïù¥ÎØ∏ÏßÄ Î°úÎìú\n",
    "filters = {\n",
    "    \"neutral\": cv2.imread('neutral.png', cv2.IMREAD_UNCHANGED),\n",
    "    \"eyeclosed_neutral\": cv2.imread('eyeclosed_neutral.png', cv2.IMREAD_UNCHANGED),\n",
    "    \"mouth_open\": cv2.imread('mouth_open.png', cv2.IMREAD_UNCHANGED),\n",
    "    \"eyeclosed_mouthopen\": cv2.imread('eyeclosed_mouthopen.png', cv2.IMREAD_UNCHANGED),\n",
    "    \"happy\": cv2.imread('happy.png', cv2.IMREAD_UNCHANGED),\n",
    "    \"eyeclosed_happy\": cv2.imread('eyeclosed_happy.png', cv2.IMREAD_UNCHANGED),\n",
    "    \"veryhappy\": cv2.imread('veryhappy.png', cv2.IMREAD_UNCHANGED),\n",
    "}\n",
    "\n",
    "# Mediapipe Ï¥àÍ∏∞Ìôî\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_hands = mp.solutions.hands\n",
    "face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True)\n",
    "hands = mp_hands.Hands(max_num_hands=2, min_detection_confidence=0.7)\n",
    "\n",
    "# EAR Í≥ÑÏÇ∞ Ìï®Ïàò\n",
    "def get_ear(landmarks, indices, w, h):\n",
    "    pts = [(int(landmarks[i].x * w), int(landmarks[i].y * h)) for i in indices]\n",
    "    A = np.linalg.norm(np.array(pts[1]) - np.array(pts[5]))\n",
    "    B = np.linalg.norm(np.array(pts[2]) - np.array(pts[4]))\n",
    "    C = np.linalg.norm(np.array(pts[0]) - np.array(pts[3]))\n",
    "    return (A + B) / (2.0 * C)\n",
    "\n",
    "# ÏûÖ Î≤åÎ¶º ÌåêÎã® Ìï®Ïàò\n",
    "def get_mouth_opening(landmarks, h):\n",
    "    return abs(landmarks[13].y - landmarks[14].y) * h\n",
    "\n",
    "# ÎØ∏ÏÜå ÌåêÎã® Ìï®Ïàò\n",
    "def is_smiling(landmarks, w, h):\n",
    "    left = landmarks[61]\n",
    "    right = landmarks[291]\n",
    "    top = landmarks[13]\n",
    "    bottom = landmarks[14]\n",
    "    mouth_width = abs(right.x - left.x) * w\n",
    "    mouth_height = abs(bottom.y - top.y) * h\n",
    "    ratio = mouth_width / (mouth_height + 1e-6)\n",
    "    return ratio > 2.2\n",
    "\n",
    "# ÏÜêÏùÑ Í∞àÏÉâÏúºÎ°ú Ïπ†ÌïòÎäî Ìï®Ïàò\n",
    "def draw_hand_mask(image, hand_landmarks, color=(60, 40, 20), alpha=0.5):\n",
    "    h, w, _ = image.shape\n",
    "    overlay = image.copy()\n",
    "    for lm in hand_landmarks.landmark:\n",
    "        x, y = int(lm.x * w), int(lm.y * h)\n",
    "        cv2.circle(overlay, (x, y), 20, color, -1)\n",
    "    cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0, image)\n",
    "\n",
    "# ÌïÑÌÑ∞ Ïò§Î≤ÑÎ†àÏù¥ Ìï®Ïàò\n",
    "def overlay_filter(frame, filter_img, x, y, w, h):\n",
    "    filter_resized = cv2.resize(filter_img, (w, h))\n",
    "    alpha = filter_resized[:, :, 3] / 255.0\n",
    "    for c in range(3):\n",
    "        frame[y:y+h, x:x+w, c] = (1 - alpha) * frame[y:y+h, x:x+w, c] + alpha * filter_resized[:, :, c]\n",
    "\n",
    "# ÏõπÏ∫† Ïã§Ìñâ\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w, _ = frame.shape\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    face_result = face_mesh.process(rgb)\n",
    "    hand_result = hands.process(rgb)\n",
    "\n",
    "    # ÏÜê Í∞àÏÉâ Ï≤òÎ¶¨\n",
    "    if hand_result.multi_hand_landmarks:\n",
    "        for hand in hand_result.multi_hand_landmarks:\n",
    "            draw_hand_mask(frame, hand)\n",
    "\n",
    "    # ÏñºÍµ¥ ÌïÑÌÑ∞ Ï≤òÎ¶¨\n",
    "    if face_result.multi_face_landmarks:\n",
    "        for landmarks in face_result.multi_face_landmarks:\n",
    "            ear_l = get_ear(landmarks.landmark, [33, 160, 158, 133, 153, 144], w, h)\n",
    "            ear_r = get_ear(landmarks.landmark, [362, 385, 387, 263, 373, 380], w, h)\n",
    "            eye_closed = (ear_l + ear_r) / 2 < 0.2\n",
    "            mouth_open = get_mouth_opening(landmarks.landmark, h) > 15\n",
    "            smiling = is_smiling(landmarks.landmark, w, h)\n",
    "\n",
    "            # ÏñºÍµ¥ ÏúÑÏπò Í≥ÑÏÇ∞\n",
    "            xs = [lm.x for lm in landmarks.landmark]\n",
    "            ys = [lm.y for lm in landmarks.landmark]\n",
    "            min_x, max_x = int(min(xs) * w), int(max(xs) * w)\n",
    "            min_y, max_y = int(min(ys) * h), int(max(ys) * h)\n",
    "            face_w, face_h = max_x - min_x, max_y - min_y\n",
    "            cx = max(0, min(min_x - face_w // 10, w - 1))\n",
    "            cy = max(0, min(min_y - face_h // 3, h - 1))\n",
    "            cw = min(int(face_w * 1.2), w - cx)\n",
    "            ch = min(int(face_h * 1.5), h - cy)\n",
    "\n",
    "            # ÌëúÏ†ïÏóê ÎßûÎäî ÌÇ§ ÏÑ†ÌÉù\n",
    "            if smiling and mouth_open:\n",
    "                key = \"veryhappy\"\n",
    "            elif smiling and eye_closed:\n",
    "                key = \"eyeclosed_happy\"\n",
    "            elif smiling:\n",
    "                key = \"happy\"\n",
    "            elif mouth_open and eye_closed:\n",
    "                key = \"eyeclosed_mouthopen\"\n",
    "            elif mouth_open:\n",
    "                key = \"mouth_open\"\n",
    "            elif eye_closed:\n",
    "                key = \"eyeclosed_neutral\"\n",
    "            else:\n",
    "                key = \"neutral\"\n",
    "\n",
    "            # ÌïÑÌÑ∞ Ïò§Î≤ÑÎ†àÏù¥\n",
    "            overlay_filter(frame, filters[key], cx, cy, cw, ch)\n",
    "\n",
    "    cv2.imshow(\"üêøÔ∏è Squirrel Vtuber\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86072bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True)\n",
    "\n",
    "mask_img = cv2.imread(\"happy.png\", cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "def rotate_image(img, angle):\n",
    "    h, w = img.shape[:2]\n",
    "    center = (w//2, h//2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    return cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "def overlay_image(bg, fg, x, y):\n",
    "    h, w = fg.shape[:2]\n",
    "    if x<0 or y<0 or x+w>bg.shape[1] or y+h>bg.shape[0]:\n",
    "        return bg\n",
    "    alpha = fg[:,:,3]/255.0\n",
    "    for c in range(3):\n",
    "        bg[y:y+h, x:x+w, c] = (1-alpha)*bg[y:y+h, x:x+w, c] + alpha*fg[:,:,c]\n",
    "    return bg\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)  # ÏûÖÎ†•ÏùÑ Î∞îÎ°ú Î∞òÏ†Ñ\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = face_mesh.process(rgb)\n",
    "\n",
    "    if result.multi_face_landmarks:\n",
    "        lm = result.multi_face_landmarks[0].landmark\n",
    "        h, w = frame.shape[:2]\n",
    "\n",
    "        left_eye = lm[33]\n",
    "        right_eye = lm[263]\n",
    "        nose = lm[1]\n",
    "\n",
    "        dx = (right_eye.x-left_eye.x)*w\n",
    "        dy = (right_eye.y-left_eye.y)*h\n",
    "        angle = -np.degrees(np.arctan2(dy, dx))\n",
    "\n",
    "        eye_dist = np.sqrt(dx**2+dy**2)\n",
    "        scale = eye_dist / mask_img.shape[1] * 2.2\n",
    "\n",
    "        new_w = int(mask_img.shape[1]*scale)\n",
    "        new_h = int(mask_img.shape[0]*scale)\n",
    "\n",
    "        resized = cv2.resize(mask_img, (new_w, new_h))\n",
    "        rotated = rotate_image(resized, angle)\n",
    "\n",
    "        x = int(nose.x*w - new_w/2)\n",
    "        y = int(nose.y*h - new_h/2)\n",
    "\n",
    "        frame = overlay_image(frame, rotated, x, y)\n",
    "\n",
    "    cv2.imshow(\"Mask\", frame)  # ÏµúÏ¢Ö flip ÌïÑÏöî ÏóÜÏùå\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "angle = -np.degrees(np.arctan2(dy, dx))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f2da908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True)\n",
    "\n",
    "# ÏÇ¨Ïö©Ìï† Í∞ÄÎ©¥ Ïù¥ÎØ∏ÏßÄ ÎØ∏Î¶¨ Î°úÎìú\n",
    "masks = {\n",
    "    \"neutral\": cv2.imread(\"neutral.png\", cv2.IMREAD_UNCHANGED),\n",
    "    \"eyeclosed_neutral\": cv2.imread(\"eyeclosed_neutral.png\", cv2.IMREAD_UNCHANGED),\n",
    "    \"happy\": cv2.imread(\"happy.png\", cv2.IMREAD_UNCHANGED),\n",
    "    \"eyeclosed_happy\": cv2.imread(\"eyeclosed_happy.png\", cv2.IMREAD_UNCHANGED),\n",
    "    \"mouthopen\": cv2.imread(\"mouth_open.png\", cv2.IMREAD_UNCHANGED),\n",
    "    \"eyeclosed_mouthopen\": cv2.imread(\"eyeclosed_mouthopen.png\", cv2.IMREAD_UNCHANGED),\n",
    "}\n",
    "\n",
    "# Îàà Í∞êÍπÄ ÎπÑÏú® Í≥ÑÏÇ∞\n",
    "def eye_aspect_ratio(lm, idx, w, h):\n",
    "    p1, p2, p3, p4, p5, p6 = [lm[i] for i in idx]\n",
    "    p1 = np.array([p1.x*w, p1.y*h])\n",
    "    p4 = np.array([p4.x*w, p4.y*h])\n",
    "    vertical1 = np.linalg.norm(np.array([p2.x*w, p2.y*h]) - np.array([p6.x*w, p6.y*h]))\n",
    "    vertical2 = np.linalg.norm(np.array([p3.x*w, p3.y*h]) - np.array([p5.x*w, p5.y*h]))\n",
    "    horizontal = np.linalg.norm(p1 - p4)\n",
    "    return (vertical1 + vertical2) / (2.0 * horizontal)\n",
    "\n",
    "# ÌöåÏ†Ñ\n",
    "def rotate_image(img, angle):\n",
    "    h, w = img.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    return cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "# Ìï©ÏÑ±\n",
    "def overlay_image(bg, fg, x, y):\n",
    "    h, w = fg.shape[:2]\n",
    "    if x < 0 or y < 0 or x + w > bg.shape[1] or y + h > bg.shape[0]:\n",
    "        return bg\n",
    "    alpha = fg[:, :, 3] / 255.0\n",
    "    for c in range(3):\n",
    "        bg[y:y+h, x:x+w, c] = (1-alpha) * bg[y:y+h, x:x+w, c] + alpha * fg[:, :, c]\n",
    "    return bg\n",
    "\n",
    "LEFT_EYE_IDX = [33, 160, 158, 133, 153, 144]\n",
    "RIGHT_EYE_IDX = [362, 385, 387, 263, 373, 380]\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = face_mesh.process(rgb)\n",
    "\n",
    "    if result.multi_face_landmarks:\n",
    "        lm = result.multi_face_landmarks[0].landmark\n",
    "        h, w = frame.shape[:2]\n",
    "\n",
    "        # Í∏∞Î≥∏ landmark\n",
    "        left_eye = lm[33]\n",
    "        right_eye = lm[263]\n",
    "        nose = lm[1]\n",
    "\n",
    "        dx = (right_eye.x - left_eye.x) * w\n",
    "        dy = (right_eye.y - left_eye.y) * h\n",
    "        angle = -np.degrees(np.arctan2(dy, dx))\n",
    "\n",
    "        # ÏñºÍµ¥ ÎÜíÏù¥ Í≥ÑÏÇ∞ (Ïù¥Îßà~ÌÑ±)\n",
    "        forehead = lm[10]\n",
    "        chin = lm[152]\n",
    "        face_height = np.sqrt(((forehead.x - chin.x) * w) ** 2 +\n",
    "                              ((forehead.y - chin.y) * h) ** 2)\n",
    "\n",
    "        # Îàà, ÏûÖ ÌäπÏßï Í≥ÑÏÇ∞\n",
    "        eye_left = eye_aspect_ratio(lm, LEFT_EYE_IDX, w, h)\n",
    "        eye_right = eye_aspect_ratio(lm, RIGHT_EYE_IDX, w, h)\n",
    "        eye_avg = (eye_left + eye_right) / 2.0\n",
    "        is_eye_closed = eye_avg < 0.22  # Í∞íÏùÄ ÏÉÅÌô©Ïóê ÎßûÍ≤å ÌäúÎãù\n",
    "\n",
    "        mouth_w = np.linalg.norm(np.array([lm[61].x*w, lm[61].y*h]) -\n",
    "                                 np.array([lm[291].x*w, lm[291].y*h]))\n",
    "        mouth_h = np.linalg.norm(np.array([lm[13].x*w, lm[13].y*h]) -\n",
    "                                 np.array([lm[14].x*w, lm[14].y*h]))\n",
    "\n",
    "        is_mouth_open = mouth_h > 18\n",
    "        is_smiling = (mouth_w / mouth_h > 2.0) and not is_mouth_open\n",
    "\n",
    "        # Í∞ÄÎ©¥ ÏÑ†ÌÉù\n",
    "        if is_mouth_open:\n",
    "            mask_key = \"eyeclosed_mouthopen\" if is_eye_closed else \"mouthopen\"\n",
    "        elif is_smiling:\n",
    "            mask_key = \"eyeclosed_happy\" if is_eye_closed else \"happy\"\n",
    "        else:\n",
    "            mask_key = \"eyeclosed_neutral\" if is_eye_closed else \"neutral\"\n",
    "\n",
    "        mask_img = masks[mask_key]\n",
    "\n",
    "        # ÏñºÍµ¥ ÎÜíÏù¥Ïóê ÎßûÏ∂∞ Ïä§ÏºÄÏùº Ï°∞Ï†ï\n",
    "        scale = face_height / mask_img.shape[0] * 1.2\n",
    "        new_w = int(mask_img.shape[1] * scale)\n",
    "        new_h = int(mask_img.shape[0] * scale * 1.2)  # ÏÑ∏Î°úÎßå 1.2Î∞∞\n",
    "\n",
    "        resized = cv2.resize(mask_img, (new_w, new_h))\n",
    "        rotated = rotate_image(resized, angle)\n",
    "\n",
    "        # ÏΩî Í∏∞Ï§Ä ÏúÑÏπò (ÏÇ¥Ïßù ÏúÑÎ°ú Ïò¨Î¶º)\n",
    "        x = int(nose.x * w - new_w // 2)\n",
    "        y = int(nose.y * h - new_h * 0.55)\n",
    "\n",
    "        frame = overlay_image(frame, rotated, x, y)\n",
    "\n",
    "    cv2.imshow(\"Mask\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed961d6a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
