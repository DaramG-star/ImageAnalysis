{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b303a48",
   "metadata": {},
   "source": [
    "### ì–¼êµ´ í•„í„° ì ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6109c794",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 59\u001b[0m\n\u001b[0;32m     55\u001b[0m                 overlay_filter(frame, filter_img, x1, y1, filter_w, filter_h)\n\u001b[0;32m     57\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSquirrel Filter ğŸ¿ï¸\u001b[39m\u001b[38;5;124m'\u001b[39m, frame)\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     62\u001b[0m cap\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# ëŒì¥ í•„í„° ì´ë¯¸ì§€ (íˆ¬ëª… PNG)\n",
    "filter_img = cv2.imread('squirrel1.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# mediapipe ì–¼êµ´ ê²€ì¶œ ì´ˆê¸°í™”\n",
    "mp_face = mp.solutions.face_detection\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "face_detection = mp_face.FaceDetection(model_selection=0, min_detection_confidence=0.5)\n",
    "\n",
    "# í•„í„° ì˜¤ë²„ë ˆì´ í•¨ìˆ˜\n",
    "def overlay_filter(frame, filter_img, x, y, w, h):\n",
    "    filter_resized = cv2.resize(filter_img, (w, h))\n",
    "\n",
    "    for c in range(3):  # BGR ì±„ë„\n",
    "        frame[y:y+h, x:x+w, c] = frame[y:y+h, x:x+w, c] * (1 - filter_resized[:, :, 3]/255.0) + \\\n",
    "                                 filter_resized[:, :, c] * (filter_resized[:, :, 3]/255.0)\n",
    "\n",
    "# ì›¹ìº  ì—´ê¸°\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # ì¢Œìš° ë°˜ì „\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w, _ = frame.shape\n",
    "\n",
    "    # ì–¼êµ´ ê°ì§€\n",
    "    results = face_detection.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    if results.detections:\n",
    "        for detection in results.detections:\n",
    "            bboxC = detection.location_data.relative_bounding_box\n",
    "            x = int(bboxC.xmin * w)\n",
    "            y = int(bboxC.ymin * h)\n",
    "            box_w = int(bboxC.width * w)\n",
    "            box_h = int(bboxC.height * h)\n",
    "\n",
    "            # ì–¼êµ´ ê¸°ì¤€ìœ¼ë¡œ í•„í„° ìœ„ì¹˜ ì¡°ì • (ì´ë§ˆ ìª½ìœ¼ë¡œ ìœ„ë¡œ ì´ë™)\n",
    "            offset_y = int(box_h * 0.4)\n",
    "            x1 = max(0, x - int(box_w * 0.2))\n",
    "            y1 = max(0, y - offset_y)\n",
    "            x2 = min(w, x1 + int(box_w * 1.4))\n",
    "            y2 = min(h, y1 + int(box_h * 1.5))\n",
    "\n",
    "            filter_w = x2 - x1\n",
    "            filter_h = y2 - y1\n",
    "\n",
    "            if filter_w > 0 and filter_h > 0:\n",
    "                overlay_filter(frame, filter_img, x1, y1, filter_w, filter_h)\n",
    "\n",
    "    cv2.imshow('Squirrel Filter ğŸ¿ï¸', frame)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c16b9e",
   "metadata": {},
   "source": [
    "#### ëˆˆê°ìœ¼ë©´ ë‹¤ë¥¸ ê°€ë©´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91c573b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SSAFY\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 32\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# ë‘ ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "filter_eye_closed = cv2.imread('squirrel1.png', cv2.IMREAD_UNCHANGED)\n",
    "filter_eye_open = cv2.imread('squirrel2.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# mediapipe ì´ˆê¸°í™”\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True, min_detection_confidence=0.5)\n",
    "\n",
    "# ëˆˆ ê°ê¹€ íŒë‹¨ í•¨ìˆ˜ (EAR ê³„ì‚°)\n",
    "def get_ear(landmarks, indices, img_w, img_h):\n",
    "    pts = [(int(landmarks[i].x * img_w), int(landmarks[i].y * img_h)) for i in indices]\n",
    "    A = np.linalg.norm(np.array(pts[1]) - np.array(pts[5]))\n",
    "    B = np.linalg.norm(np.array(pts[2]) - np.array(pts[4]))\n",
    "    C = np.linalg.norm(np.array(pts[0]) - np.array(pts[3]))\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "# í•„í„° ì˜¤ë²„ë ˆì´ í•¨ìˆ˜\n",
    "def overlay_filter(frame, filter_img, x, y, w, h):\n",
    "    filter_resized = cv2.resize(filter_img, (w, h))\n",
    "    for c in range(3):\n",
    "        frame[y:y+h, x:x+w, c] = frame[y:y+h, x:x+w, c] * (1 - filter_resized[:, :, 3]/255.0) + \\\n",
    "                                 filter_resized[:, :, c] * (filter_resized[:, :, 3]/255.0)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w, _ = frame.shape\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # ëˆˆ ê°ê¹€ íŒë‹¨ìš© ì¢Œí‘œ\n",
    "            left_eye_indices = [33, 160, 158, 133, 153, 144]\n",
    "            right_eye_indices = [362, 385, 387, 263, 373, 380]\n",
    "            left_ear = get_ear(face_landmarks.landmark, left_eye_indices, w, h)\n",
    "            right_ear = get_ear(face_landmarks.landmark, right_eye_indices, w, h)\n",
    "            avg_ear = (left_ear + right_ear) / 2.0\n",
    "\n",
    "            # ì–¼êµ´ ì „ì²´ ë°•ìŠ¤ ì¢Œí‘œ êµ¬í•˜ê¸°\n",
    "            xs = [lm.x for lm in face_landmarks.landmark]\n",
    "            ys = [lm.y for lm in face_landmarks.landmark]\n",
    "            min_x = int(min(xs) * w)\n",
    "            max_x = int(max(xs) * w)\n",
    "            min_y = int(min(ys) * h)\n",
    "            max_y = int(max(ys) * h)\n",
    "\n",
    "            face_w = max_x - min_x\n",
    "            face_h = max_y - min_y\n",
    "            cx = min_x - int(face_w * 0.1)\n",
    "            cy = min_y - int(face_h * 0.4)\n",
    "            cw = int(face_w * 1.2)\n",
    "            ch = int(face_h * 1.5)\n",
    "\n",
    "            # ëˆˆ ê°ì•˜ëŠ”ì§€ì— ë”°ë¼ í•„í„° ì„ íƒ\n",
    "            filter_to_use = filter_eye_closed if avg_ear < 0.2 else filter_eye_open\n",
    "\n",
    "            # ì˜¤ë²„ë ˆì´\n",
    "            cx = max(0, min(cx, w - cw))\n",
    "            cy = max(0, min(cy, h - ch))\n",
    "            overlay_filter(frame, filter_to_use, cx, cy, cw, ch)\n",
    "\n",
    "    cv2.imshow(\"Squirrel Filter ğŸ¿ï¸\", frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed961d6a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
